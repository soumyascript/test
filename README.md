#  MedTrain Sync Process Documentation

## Overview
The **MedTrain Sync Process** automates the transfer of training session data â€” including JSON logs and PDF reports â€” from **local systems** to the **development (cloud) environment**.
This ensures seamless data sharing, auditability, and reliability across training centers.

---

##  Step-by-Step Process

### 1. Session Creation
**When:** A user completes a training session on a medical manikin.

**System Actions:**
- âœ… Saves session metadata into **local PostgreSQL database**
- âœ… Generates **PDF report** (performance summary)
- âœ… Creates **JSON data file** (raw sensor + event data)
- âœ… Stores both files in local storage (e.g., `/home/medtrain/logs/sessions/`)

---

### 2. Cron-Based Sync Activation
**Trigger:** A background cron job runs every **5 minutes**

**Example Cron Expression:**
*/5 * * * * /usr/bin/node /path/to/syncJob.js >> /var/log/medtrain/sync.log 2>&1

**System Actions:**
- ğŸ” Scans local DB for unsynced sessions
- ğŸ§¾ Verifies PDF/JSON existence
- ğŸ“¦ Queues new sessions for upload and sync

---

### 3. Cloud File Upload
**Process:** Uploads local files to **DigitalOcean Spaces (S3-compatible)**

**Files:**
- `session_<id>.pdf`
- `session_<id>.json`

**Example URLs:**
https://devSensorlog.nyc3.digitaloceanspaces.com/session_123.pdf

https://devSensorlog.nyc3.digitaloceanspaces.com/session_123.json

Each uploaded file returns a **public URL**, which is stored for reference in both databases.

---

### 4. Two-Phase Commit Process
To maintain **transactional integrity** between **local DB** and **development DB**, the sync service uses a **two-phase commit approach**:

#### Phase 1 â€“ Prepare (Validation)
1. Validate session completeness (PDF + JSON + metadata)
2. Upload files to cloud (DigitalOcean)
3. Create a transaction record in the local DB (`sync_status = pending`)
4. Test connectivity with dev database

#### Phase 2 â€“ Commit (Finalization)
1. Insert session data into **development database**
2. Update **file URLs** (PDF/JSON) in dev DB
3. Mark transaction as **committed** in local DB (`sync_status = done`)
4. Log success in local sync history

> âš ï¸ If any step fails (e.g., upload or DB insert),
> the transaction is **rolled back** and retried in the next cron cycle.

---

### 5. Development Database Update
**Process:** Replicates and enriches session data in **dev environment**

**Actions:**
- ğŸ“¥ Inserts session rows from local DB
- ğŸ”— Updates `pdf_url` and `json_url` columns
- ğŸ¯ Maintains primary key mapping and integrity

---

### 6. Sync Completion
Once all operations succeed:
- ğŸ·ï¸ Marks session as `synced = true` in local DB
- ğŸ•’ Adds entry in `sync_history` table
- â­ï¸ Excludes synced sessions from future scans

---

### 7. Development Team Access
The synced data becomes available instantly on the **MedTrain Dev Dashboard**:

- ğŸ‘€ View session summaries
- ğŸ“¥ Download JSON/PDF via cloud URLs
- ğŸ“Š Analyze performance and metrics
- ğŸ”„ Real-time visibility across all connected devices

---

## System Architecture Diagram

```mermaid
graph TB
    A[ğŸ¥ User Session<br/>Medical Training] --> B[ğŸ’» Local Application<br/>Node.js Service]
    
    B --> C[ğŸ—ƒï¸ Local Database<br/>PostgreSQL]
    B --> D[ğŸ“ Local File Storage<br/>PDF + JSON Files]
    
    C --> E[â° Sync Scheduler<br/>Every 5 Minutes]
    D --> E
    
    E --> F[ğŸ”„ Two-Phase Commit<br/>Upload Process]
    
    F --> G[â˜ï¸ DigitalOcean Spaces<br/>Cloud File Storage]
    F --> H[ğŸŒ Development Database<br/>PostgreSQL]
    
    G --> I[ğŸ“Š MedTrain Dev Dashboard]
    H --> I
    
    subgraph "Local Environment"
        C
        D
    end
    
    subgraph "Sync Process"
        E
        F
    end
    
    subgraph "Development Environment"
        G
        H
        I
    end

    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
    style E fill:#fff9c4
    style F fill:#ffebee
    style G fill:#e0f2f1
    style H fill:#fce4ec
    style I fill:#e8eaf6
```
---

## Summary of Sync Lifecycle

| Stage | Action           | Responsibility     | Outcome                     |
| ----- | ---------------- | ------------------ | --------------------------- |
| **1** | Session Created  | Local Node Service | Data stored locally         |
| **2** | Cron Triggered   | Sync Service       | Unsynced sessions detected  |
| **3** | Upload Files     | S3 Client          | Files uploaded to cloud     |
| **4** | Two-Phase Commit | Sync Controller    | Data consistency ensured    |
| **5** | Update Dev DB    | API/DB Connector   | URLs & data stored in dev   |
| **6** | Mark Complete    | Local DB           | Session marked as synced    |
| **7** | Dev Access       | MedTrain UI        | Team can view/download data |

---

## Reliability & Retry Logic
- Retries every **cron cycle** if sync fails
- Each failure logged with reason (network, upload, or DB error)
- No duplicate inserts due to unique `session_id` validation
- Status flags used:
  - `pending` â†’ `in_progress` â†’ `done` â†’ `error`

---

## Technical Components

| **Component**            | **Function**                               | **Analogy**               |
| ------------------------ | ------------------------------------------ | ------------------------- |
| **Local Database**       | Stores session details and metadata        | Personal Notebook         |
| **Local File Storage**   | Holds PDF reports and JSON data            | File Cabinet              |
| **DigitalOcean Spaces**  | Cloud-based file storage system            | Secure Google Drive       |
| **Development Database** | Centralized data for team access           | Shared Company Notebook   |
| **Sync Service**         | Automated data transfer + two-phase commit | Reliable Delivery Service |
| **Cron Job**             | Periodic trigger for sync process          | Alarm Clock               |

---

## Key Benefits

- ğŸ”„ **Fully automated, self-healing sync pipeline**
- ğŸ”’ **Secure data handling with S3-compatible cloud**
- ğŸ§  **Atomic data transfer (no partial syncs)**
- ğŸ“ˆ **Real-time data visibility for the dev team**
- âš¡ **Optimized for performance and low bandwidth**
- ğŸ› ï¸ **Robust error handling + detailed logging**

---

## Summary
Every session goes through the following lifecycle:
1. Captured locally
2. Saved as JSON and PDF
3. Uploaded to DigitalOcean
4. Committed to Dev DB via two-phase sync
5. Marked as completed

> **Result:** A reliable, secure, and traceable sync from manikin â†’ local system â†’ MedTrain Cloud Dashboard.
